{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building MultiModal Search with Vector Databases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how build multi-modal search (image, audio, video) `Meta AI ImageBind` model ([multi2vec-bind](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/multi2vec-bind)).\n",
    "\n",
    "ImageBind allows us to search through text, images, audio and video files.\n",
    "\n",
    "This recipe will focus on searching through image, audio and video:\n",
    "\n",
    "* [text-to-media search](#text-to-media-search) - provide text as input to search through media\n",
    "* [image-to-media search](#image-to-media-search) - provide image as input to search through media\n",
    "* [audio-to-media search](#audio-to-media-search) - provide audio as input to search through media\n",
    "* [video-to-media search](#video-to-media-search) - provide video as input to search through media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weaviate Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageBind model is only available with local Weaviate deployments with Docker or Kubernetes.\n",
    "\n",
    "ImageBind is not supported with Weaviate Cloud Services (WCS).\n",
    "\n",
    "### Steps to deploy Weaviate locally with ImageBind\n",
    "\n",
    "1. Locate a docker compose file.\n",
    "    There is a prepared docker compose file at `/2-multimodal/docker-compose.yml`, which contains the necessary configuration to run Weaviate with `Meta's ImageBind` model.\n",
    "\n",
    "    Navigate to the multimodal folder:\n",
    "    ```\n",
    "    cd 2-multimodal\n",
    "    ```\n",
    "\n",
    "2. Run Weaviate & ImageBind with Docker Compose\n",
    "\n",
    "    > If you are new to `Docker Compose`, [here are instructions on how to install it](https://docs.docker.com/compose/install/).\n",
    "\n",
    "    To start the docker image defined in the `docker-compose.yml` file, call:\n",
    "\n",
    "    ```bash\n",
    "    docker compose up\n",
    "    ```\n",
    "    \n",
    "    > Note #1 - the first time you run the command, Docker will download a ~6GB image.\n",
    "    \n",
    "    > Note #2 – after the image is downloaded (or when we restart the image), it usually takes 30-60 seconds for the image to be ready.\n",
    "\n",
    "    > Note #3 – to shut down a running docker image, press CMD+C or CTRL+C.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "    1. The Weaviate Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --pre -I \"weaviate-client==4.4.b1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate, os\n",
    "import weaviate.classes as wvc\n",
    "\n",
    "# Connect to your local Docker instance\n",
    "# TODO\n",
    "client = None\n",
    "\n",
    "# And check if the connection is ready\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `Animals` Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.Collection at 0x10a897350>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's delete the collection in case you want to rerun this code\n",
    "if(client.collections.exists(\"Animals\")):\n",
    "    client.collections.delete(\"Animals\")\n",
    "\n",
    "# Create a new collection with multi2vec bind\n",
    "# use audio, image and video as the media fields\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Helper function to convert a file to base64 representation\n",
    "def toBase64(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Images into Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = os.listdir(\"./source/image/\")\n",
    "\n",
    "items = list()\n",
    "\n",
    "for name in source:\n",
    "    \n",
    "    print(f\"Adding {name}\")\n",
    "    \n",
    "    path = \"./source/image/\" + name\n",
    "    \n",
    "    items.append({\n",
    "        \"name\": name,\n",
    "        \"path\": path,\n",
    "        \"image\": toBase64(path),\n",
    "        \"mediaType\": \"image\"\n",
    "    })\n",
    "\n",
    "# TODO - connect get the animals collection\n",
    "# and insert the images\n",
    "\n",
    "\n",
    "# it is fine to insert all 9 items in one go\n",
    "# but if we deal with bigger objects like videos or audio, then we should load them in smaller batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check object count\n",
    "animals = client.collections.get(\"Animals\")\n",
    "animals.aggregate.over_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Audio Files into Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = client.collections.get(\"Animals\")\n",
    "\n",
    "source = os.listdir(\"./source/audio/\")\n",
    "\n",
    "items = []\n",
    "counter = 0\n",
    "\n",
    "for name in source:\n",
    "    print(f\"Adding {name}\")\n",
    "    \n",
    "    path = \"./source/audio/\" + name\n",
    "    items.append({\n",
    "        \"name\": name,\n",
    "        \"path\": path,\n",
    "        \"audio\": toBase64(path),\n",
    "        \"mediaType\": \"audio\"\n",
    "    })\n",
    "\n",
    "    # TODO - load items in batches of 3, and clear\n",
    "\n",
    "# TODO - Insert any remaining items\n",
    "if (len(items) > 0):\n",
    "    print(f\"Inserting remaining ({len(items)}) items. Total counter: {counter}\")\n",
    "    # TODO add code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check object count again\n",
    "animals.aggregate.over_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Video Files into Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = client.collections.get(\"Animals\")\n",
    "\n",
    "source = os.listdir(\"./source/video/\")\n",
    "\n",
    "for name in source:\n",
    "    print(f\"Adding {name}\")\n",
    "    \n",
    "    path = \"./source/video/\" + name\n",
    "    item = {\n",
    "        \"name\": name,\n",
    "        \"path\": path,\n",
    "        \"video\": toBase64(path),\n",
    "        \"mediaType\": \"video\"\n",
    "    }\n",
    "    \n",
    "    # Videos are big, so we should avoid inserting them in bulk\n",
    "    # TODO: insert video objects one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_AggregateReturn(properties={}, total_count=26)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the object count again\n",
    "animals.aggregate.over_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - let's group by \"mediaType\" to see how many objects we have per each group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check all the media files added to the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = animals.iterator(\n",
    "    return_properties=[\"name\", \"mediaType\"],\n",
    "    # include_vector=True, # in case you want to see the vectors\n",
    ")\n",
    "\n",
    "for item in itr:\n",
    "    print(item.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Search\n",
    "\n",
    "> Note, this usually should exist in a separe file/flow, as we shouldn't keep collection creation (which is usually a one-off process) and data import – together with queries (this is usually what you use on a daily basis). As to avoid recreating the collection and importing the data.\n",
    "\n",
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to display results\n",
    "import json\n",
    "from IPython.display import Image, Audio, Video\n",
    "\n",
    "def json_print(data):\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n",
    "def display_media(item):\n",
    "    path = item[\"path\"]\n",
    "\n",
    "    if(item[\"mediaType\"] == \"image\"):\n",
    "        display(Image(path))\n",
    "\n",
    "    elif(item[\"mediaType\"] == \"video\"):\n",
    "        display(Video(path))\n",
    "        \n",
    "    elif(item[\"mediaType\"] == \"audio\"):\n",
    "        display(Audio(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, requests\n",
    "\n",
    "# Helper function – get base64 representation from an online image\n",
    "def url_to_base64(url):\n",
    "    image_response = requests.get(url)\n",
    "    content = image_response.content\n",
    "    return base64.b64encode(content).decode('utf-8')\n",
    "\n",
    "# Helper function - get base64 representation from a local file\n",
    "def file_to_base64(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')\n",
    "\n",
    "# Update the url and path to test\n",
    "#test_image_base64 = url_to_base64(\"https://path-to-some-online-image.jpg\")\n",
    "#test_file_base64 = file_to_base64(\"./test/meerkat.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='text-to-media-search'></a>\n",
    "### Text to Media Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use near text to search for \"dog with stick\" and return 3 items\n",
    "# TODO: make sure we capture the result as \"response\" \n",
    "# response = animals.query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "for obj in response.objects:\n",
    "    json_print(obj.properties)\n",
    "    display_media(obj.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='image-to-media-search'></a>\n",
    "### Image to Media Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"./test/test-cat.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use near image to search with \"./test/test-cat.jpg\" and return 3 items\n",
    "# HINT: use toBase64 to convert the file to base64\n",
    "#    or use Path(\"./your-file-path-here\"),\n",
    "# response = animals.query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in response.objects:\n",
    "    json_print(obj.properties)\n",
    "    display_media(obj.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='audio-to-media-search'></a>\n",
    "### Audio to Media Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(\"./test/dog_audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use near audio to search with \"./test/dog_audio.wav\" and return 3 items\n",
    "# HINT: use toBase64 to convert the file to base64\n",
    "\n",
    "# response = animals.query.near_audio(\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in response.objects:\n",
    "    json_print(obj.properties)\n",
    "    display_media(obj.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='video-to-media-search'></a>\n",
    "### Video to Media Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"./test/test-meerkat.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use near audio to search with \"./test/meerkat.mp4\" and return 3 items\n",
    "# HINT: use toBase64 to convert the file to base64\n",
    "\n",
    "# response = animals.query.near_video(\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in response.objects:\n",
    "    json_print(obj.properties)\n",
    "    display_media(obj.properties)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
