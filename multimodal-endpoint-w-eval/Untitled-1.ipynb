{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Endpoint with LiteLLM, ComfyUI, and Trulens\n",
    "\n",
    "This notebook is designed to serve as a backend for a multimodal system that integrates text and image generation with evaluation metrics. It leverages LiteLLM for language model completions, ComfyUI for image generation, and Trulens for response evaluation. The system is structured to handle multi-turn conversations, with each conversation's data being stored in a separate PostgreSQL table for easy tracking and analysis.\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "The notebook is organized into several sections, each contained within its own cell or group of cells:\n",
    "\n",
    "1. **Environment Setup**: Import libraries, set environment variables, and install any necessary packages.\n",
    "2. **Configuration**: Define API keys, endpoints, and global variables.\n",
    "3. **LiteLLM Completion Function**: Code to interact with LiteLLM for text generation.\n",
    "4. **ComfyUI Image Generation Function**: Code to generate images using ComfyUI based on text prompts.\n",
    "5. **File Watcher Setup**: Implement a file watcher to monitor for new images and display them.\n",
    "6. **Trulens Evaluation Setup**: Configure Trulens to evaluate responses and send data to PostgreSQL.\n",
    "7. **PostgreSQL Integration**: Functions for database interactions, including table creation and data insertion.\n",
    "8. **Main Workflow**: The main function that orchestrates the text generation, image generation, and evaluation process.\n",
    "9. **Gradio Interface (Placeholder)**: A placeholder for future integration with a Gradio front-end.\n",
    "10. **Execution and Testing**: Cells to execute the main workflow with test inputs.\n",
    "11. **Documentation and Notes**: Additional explanations and documentation for users.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The goal of this notebook is to create an endpoint that accepts text prompts, generates corresponding images, and evaluates the responses. It is designed to be part of a larger system that could include a front-end interface for user interaction. The notebook will demonstrate the backend functionality, including the integration of different APIs and tools, and the handling of multi-turn conversations with persistent storage.\n",
    "\n",
    "Please ensure that you replace any placeholder values with your actual API keys, paths, and connection strings as needed before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: psycopg2-binary in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (2.9.9)\n",
      "Requirement already satisfied: watchdog in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (3.0.0)\n",
      "Requirement already satisfied: requests in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: litellm[proxy] in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (1.15.7)\n",
      "Requirement already satisfied: aiohttp in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (3.9.1)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (1.4.4)\n",
      "Requirement already satisfied: backoff in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (2.2.1)\n",
      "Requirement already satisfied: certifi<2024.0.0,>=2023.7.22 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (2023.11.17)\n",
      "Requirement already satisfied: click in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (8.1.7)\n",
      "Requirement already satisfied: fastapi<0.105.0,>=0.104.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (0.104.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (7.0.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (3.1.2)\n",
      "Requirement already satisfied: openai>=1.0.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (1.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (1.0.0)\n",
      "Requirement already satisfied: rq in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (1.15.1)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (0.5.2)\n",
      "Requirement already satisfied: tokenizers in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (0.15.0)\n",
      "Requirement already satisfied: uvicorn<0.25.0,>=0.24.0.post1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from litellm[proxy]) (0.24.0.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from fastapi<0.105.0,>=0.104.1->litellm[proxy]) (3.7.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from fastapi<0.105.0,>=0.104.1->litellm[proxy]) (2.5.2)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from fastapi<0.105.0,>=0.104.1->litellm[proxy]) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from fastapi<0.105.0,>=0.104.1->litellm[proxy]) (4.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm[proxy]) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm[proxy]) (2.1.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from openai>=1.0.0->litellm[proxy]) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from openai>=1.0.0->litellm[proxy]) (0.25.2)\n",
      "Requirement already satisfied: sniffio in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from openai>=1.0.0->litellm[proxy]) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from openai>=1.0.0->litellm[proxy]) (4.66.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from tiktoken>=0.4.0->litellm[proxy]) (2023.12.25)\n",
      "Requirement already satisfied: h11>=0.8 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from uvicorn<0.25.0,>=0.24.0.post1->litellm[proxy]) (0.14.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from aiohttp->litellm[proxy]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from aiohttp->litellm[proxy]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from aiohttp->litellm[proxy]) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from aiohttp->litellm[proxy]) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from aiohttp->litellm[proxy]) (1.3.1)\n",
      "Requirement already satisfied: redis>=4.0.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from rq->litellm[proxy]) (5.0.1)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from tokenizers->litellm[proxy]) (0.20.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->litellm[proxy]) (1.0.2)\n",
      "Requirement already satisfied: filelock in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm[proxy]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm[proxy]) (2023.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm[proxy]) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm[proxy]) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.105.0,>=0.104.1->litellm[proxy]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi<0.105.0,>=0.104.1->litellm[proxy]) (2.14.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com, https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: hordelib in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (2.2.4)\n",
      "Requirement already satisfied: horde-sdk>=0.7.22 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.7.24)\n",
      "Requirement already satisfied: horde-model-reference>=0.5.2 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.5.3)\n",
      "Requirement already satisfied: pydantic in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (2.5.2)\n",
      "Requirement already satisfied: torch>=2.1.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (2.1.2+cu121)\n",
      "Requirement already satisfied: torchvision in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.16.2+cu121)\n",
      "Requirement already satisfied: torchaudio in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (2.1.2+cu121)\n",
      "Requirement already satisfied: torchdiffeq in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.2.3)\n",
      "Requirement already satisfied: torchsde in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.2.6)\n",
      "Requirement already satisfied: einops in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.7.0)\n",
      "Requirement already satisfied: open-clip-torch in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (2.23.0)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (4.36.2)\n",
      "Requirement already satisfied: safetensors>=0.3.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.4.1)\n",
      "Requirement already satisfied: pytorch-lightning in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (2.1.3)\n",
      "Requirement already satisfied: pynvml in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (11.5.0)\n",
      "Requirement already satisfied: aiohttp in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (3.9.1)\n",
      "Requirement already satisfied: accelerate in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.25.0)\n",
      "Requirement already satisfied: pyyaml in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (6.0.1)\n",
      "Requirement already satisfied: pillow in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (10.1.0)\n",
      "Requirement already satisfied: loguru in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.7.2)\n",
      "Requirement already satisfied: GitPython in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (3.1.40)\n",
      "Requirement already satisfied: clip-anytorch in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (2.5.2)\n",
      "Requirement already satisfied: diffusers in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.24.0)\n",
      "Requirement already satisfied: omegaconf in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (2.3.0)\n",
      "Requirement already satisfied: psutil in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (5.9.7)\n",
      "Requirement already satisfied: typing-extensions in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (4.9.0)\n",
      "Requirement already satisfied: distro in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (1.8.0)\n",
      "Requirement already satisfied: python-dotenv in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (1.0.0)\n",
      "Requirement already satisfied: strenum in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.4.15)\n",
      "Requirement already satisfied: rembg in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (2.0.53)\n",
      "Requirement already satisfied: opencv-python in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (4.8.1.78)\n",
      "Requirement already satisfied: opencv-contrib-python in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (4.8.1.78)\n",
      "Requirement already satisfied: timm==0.9.10 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.9.10)\n",
      "Requirement already satisfied: scipy in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (1.11.4)\n",
      "Requirement already satisfied: addict in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (2.4.0)\n",
      "Requirement already satisfied: fairscale in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.4.13)\n",
      "Requirement already satisfied: scikit-image in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.22.0)\n",
      "Requirement already satisfied: mediapipe>=0.9.1.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.10.9)\n",
      "Requirement already satisfied: unidecode in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (1.3.7)\n",
      "Requirement already satisfied: fuzzywuzzy in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from hordelib) (0.18.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from timm==0.9.10->hordelib) (0.20.1)\n",
      "Requirement already satisfied: requests in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from horde-model-reference>=0.5.2->hordelib) (2.31.0)\n",
      "Requirement already satisfied: aiodns in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from horde-sdk>=0.7.22->hordelib) (3.1.1)\n",
      "Requirement already satisfied: absl-py in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from mediapipe>=0.9.1.0->hordelib) (2.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from mediapipe>=0.9.1.0->hordelib) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from mediapipe>=0.9.1.0->hordelib) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from mediapipe>=0.9.1.0->hordelib) (3.8.2)\n",
      "Requirement already satisfied: numpy in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from mediapipe>=0.9.1.0->hordelib) (1.26.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from mediapipe>=0.9.1.0->hordelib) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from mediapipe>=0.9.1.0->hordelib) (0.4.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from pydantic->hordelib) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from pydantic->hordelib) (2.14.5)\n",
      "Requirement already satisfied: filelock in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from torch>=2.1.0->hordelib) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from torch>=2.1.0->hordelib) (1.12)\n",
      "Requirement already satisfied: networkx in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from torch>=2.1.0->hordelib) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from torch>=2.1.0->hordelib) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from torch>=2.1.0->hordelib) (2023.12.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from torch>=2.1.0->hordelib) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from transformers>=4.25.1->hordelib) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from transformers>=4.25.1->hordelib) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from transformers>=4.25.1->hordelib) (0.15.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from transformers>=4.25.1->hordelib) (4.66.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from aiohttp->hordelib) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from aiohttp->hordelib) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from aiohttp->hordelib) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from aiohttp->hordelib) (1.3.1)\n",
      "Requirement already satisfied: ftfy in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from clip-anytorch->hordelib) (6.1.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from diffusers->hordelib) (7.0.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from GitPython->hordelib) (4.0.11)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from omegaconf->hordelib) (4.9.3)\n",
      "Requirement already satisfied: sentencepiece in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from open-clip-torch->hordelib) (0.1.99)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from pytorch-lightning->hordelib) (1.2.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from pytorch-lightning->hordelib) (0.10.0)\n",
      "Requirement already satisfied: jsonschema in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from rembg->hordelib) (4.20.0)\n",
      "Requirement already satisfied: onnxruntime in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from rembg->hordelib) (1.16.3)\n",
      "Requirement already satisfied: opencv-python-headless in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from rembg->hordelib) (4.8.1.78)\n",
      "Requirement already satisfied: pooch in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from rembg->hordelib) (1.8.0)\n",
      "Requirement already satisfied: pymatting in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from rembg->hordelib) (1.1.12)\n",
      "Requirement already satisfied: imageio>=2.27 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from scikit-image->hordelib) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from scikit-image->hordelib) (2023.12.9)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from scikit-image->hordelib) (0.3)\n",
      "Requirement already satisfied: trampoline>=0.1.2 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from torchsde->hordelib) (0.1.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython->hordelib) (5.0.1)\n",
      "Requirement already satisfied: setuptools in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning->hordelib) (65.5.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from sounddevice>=0.4.4->mediapipe>=0.9.1.0->hordelib) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->hordelib) (3.6)\n",
      "Requirement already satisfied: pycares>=4.0.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from aiodns->horde-sdk>=0.7.22->hordelib) (4.4.0)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from ftfy->clip-anytorch->hordelib) (0.2.12)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from importlib-metadata->diffusers->hordelib) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from jinja2->torch>=2.1.0->hordelib) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from jsonschema->rembg->hordelib) (2023.11.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from jsonschema->rembg->hordelib) (0.32.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from jsonschema->rembg->hordelib) (0.15.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from matplotlib->mediapipe>=0.9.1.0->hordelib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from matplotlib->mediapipe>=0.9.1.0->hordelib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from matplotlib->mediapipe>=0.9.1.0->hordelib) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from matplotlib->mediapipe>=0.9.1.0->hordelib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from matplotlib->mediapipe>=0.9.1.0->hordelib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from matplotlib->mediapipe>=0.9.1.0->hordelib) (2.8.2)\n",
      "Requirement already satisfied: coloredlogs in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from onnxruntime->rembg->hordelib) (15.0.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from pooch->rembg->hordelib) (4.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from requests->horde-model-reference>=0.5.2->hordelib) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from requests->horde-model-reference>=0.5.2->hordelib) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from requests->horde-model-reference>=0.5.2->hordelib) (2023.11.17)\n",
      "Requirement already satisfied: numba!=0.49.0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from pymatting->rembg->hordelib) (0.58.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from sympy->torch>=2.1.0->hordelib) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.9.1.0->hordelib) (2.21)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from numba!=0.49.0->pymatting->rembg->hordelib) (0.41.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe>=0.9.1.0->hordelib) (1.16.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/anon/ubuntu-repos/runpod/.venv/lib/python3.11/site-packages (from coloredlogs->onnxruntime->rembg->hordelib) (10.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'comfyui'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/anon/ubuntu-repos/backup-plan/multimodal-endpoint-w-eval/Untitled-1.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/anon/ubuntu-repos/backup-plan/multimodal-endpoint-w-eval/Untitled-1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwatchdog\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevents\u001b[39;00m \u001b[39mimport\u001b[39;00m FileSystemEventHandler\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/anon/ubuntu-repos/backup-plan/multimodal-endpoint-w-eval/Untitled-1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Assuming ComfyUI has a Python API or CLI that can be interfaced with\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/anon/ubuntu-repos/backup-plan/multimodal-endpoint-w-eval/Untitled-1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcomfyui\u001b[39;00m \u001b[39mimport\u001b[39;00m ComfyUI\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/anon/ubuntu-repos/backup-plan/multimodal-endpoint-w-eval/Untitled-1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Prompt for API keys and sensitive information\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/anon/ubuntu-repos/backup-plan/multimodal-endpoint-w-eval/Untitled-1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m getpass(\u001b[39m\"\u001b[39m\u001b[39mEnter your OpenAI API key: \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'comfyui'"
     ]
    }
   ],
   "source": [
    "# Cell 1: Environment Setup and Package Installation\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "from getpass import getpass\n",
    "import psycopg2\n",
    "from litellm import completion\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "# Install required packages\n",
    "%pip install litellm[proxy] psycopg2-binary watchdog requests\n",
    "%pip install --extra-index-url https://download.pytorch.org/whl/cu121 hordelib\n",
    "\n",
    "\n",
    "# Prompt for API keys and sensitive information\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
    "os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your Gemini API key: \")\n",
    "os.environ[\"VERTEX_PROJECT\"] = getpass(\"Enter your Vertex project ID: \")\n",
    "os.environ[\"VERTEX_LOCATION\"] = getpass(\"Enter your Vertex location: \")\n",
    "\n",
    "# Set up global variables and paths\n",
    "IMAGE_OUTPUT_FOLDER = \"/path/to/generated_images\"  # Replace with the actual path to the image output folder\n",
    "DATABASE_FILE_PATH = \"path/to/your/directory/default.sqlite\"  # Replace with the actual path to your SQLite database file\n",
    "\n",
    "print(\"Environment setup and package installation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration Setup\n",
    "\n",
    "# Define the model names for LiteLLM completion\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "GEMINI_MODEL = \"google/gemini-model\"  # Replace with the actual model name if different\n",
    "\n",
    "# Define the path to the model cache for hordelib\n",
    "os.environ[\"AIWORKER_CACHE_HOME\"] = \"/path/to/your/models\"  # Replace with the actual path to your models\n",
    "\n",
    "print(\"Configuration setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: LiteLLM Proxy Server Configuration\n",
    "\n",
    "# Assuming the necessary packages are installed and environment variables are set from Cell 1\n",
    "# Assuming global variables and paths are set from Cell 2\n",
    "\n",
    "# Import necessary libraries\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the configuration for the LiteLLM proxy server\n",
    "config = {\n",
    "    'model_list': [\n",
    "        {\n",
    "            'model_name': 'gpt-3.5-turbo',\n",
    "            'litellm_params': {\n",
    "                'model': 'openai/gpt-3.5-turbo',\n",
    "                'api_base': 'https://api.openai.com',\n",
    "                'api_key': os.getenv(\"OPENAI_API_KEY\")\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'model_name': 'gemini-pro',\n",
    "            'litellm_params': {\n",
    "                'model': 'vertex_ai/gemini-pro',\n",
    "                'api_base': 'https://vertex-ai.google.com',\n",
    "                'api_key': os.getenv(\"GEMINI_API_KEY\")\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    'litellm_settings': {\n",
    "        'drop_params': True,\n",
    "        'set_verbose': True\n",
    "    },\n",
    "    'general_settings': {\n",
    "        'master_key': 'sk-my_special_key'  # Replace with a master key of your choice\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the config to a YAML file\n",
    "config_path = Path('config.yaml')\n",
    "with open(config_path, 'w') as config_file:\n",
    "    yaml.dump(config, config_file, default_flow_style=False)\n",
    "\n",
    "print(f\"Config file created at: {config_path.resolve()}\")\n",
    "\n",
    "# Start the LiteLLM proxy server with the config file\n",
    "!litellm --config {config_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: HTTP Error 400: Bad Request\n",
      "Request data: b'{\"prompt\": {\"3\": {\"class_type\": \"KSampler\", \"inputs\": {\"cfg\": 8, \"denoise\": 1, \"latent_image\": [\"5\", 0], \"model\": [\"4\", 0], \"negative\": [\"7\", 0], \"positive\": [\"6\", 0], \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"seed\": 8566257, \"steps\": 20}}, \"4\": {\"class_type\": \"CheckpointLoaderSimple\", \"inputs\": {\"ckpt_name\": \"v1-5-pruned-emaonly.ckpt\"}}, \"5\": {\"class_type\": \"EmptyLatentImage\", \"inputs\": {\"batch_size\": 1, \"height\": 512, \"width\": 512}}, \"6\": {\"class_type\": \"CLIPTextEncode\", \"inputs\": {\"clip\": [\"4\", 1], \"text\": \"masterpiece best quality girl\"}}, \"7\": {\"class_type\": \"CLIPTextEncode\", \"inputs\": {\"clip\": [\"4\", 1], \"text\": \"bad hands\"}}, \"8\": {\"class_type\": \"VAEDecode\", \"inputs\": {\"samples\": [\"3\", 0], \"vae\": [\"4\", 2]}}, \"9\": {\"class_type\": \"SaveImage\", \"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"8\", 0]}}}}'\n",
      "Request headers: {'Content-type': 'application/json'}\n",
      "An error occurred: HTTP Error 400: Bad Request\n",
      "Request data: b'{\"prompt\": {\"3\": {\"class_type\": \"KSampler\", \"inputs\": {\"cfg\": 8, \"denoise\": 1, \"latent_image\": [\"5\", 0], \"model\": [\"4\", 0], \"negative\": [\"7\", 0], \"positive\": [\"6\", 0], \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"seed\": 5, \"steps\": 20}}, \"4\": {\"class_type\": \"CheckpointLoaderSimple\", \"inputs\": {\"ckpt_name\": \"v1-5-pruned-emaonly.ckpt\"}}, \"5\": {\"class_type\": \"EmptyLatentImage\", \"inputs\": {\"batch_size\": 1, \"height\": 512, \"width\": 512}}, \"6\": {\"class_type\": \"CLIPTextEncode\", \"inputs\": {\"clip\": [\"4\", 1], \"text\": \"masterpiece best quality man\"}}, \"7\": {\"class_type\": \"CLIPTextEncode\", \"inputs\": {\"clip\": [\"4\", 1], \"text\": \"bad hands\"}}, \"8\": {\"class_type\": \"VAEDecode\", \"inputs\": {\"samples\": [\"3\", 0], \"vae\": [\"4\", 2]}}, \"9\": {\"class_type\": \"SaveImage\", \"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"8\", 0]}}}}'\n",
      "Request headers: {'Content-type': 'application/json'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from urllib import request, parse\n",
    "import random\n",
    "\n",
    "#This is the ComfyUI api prompt format.\n",
    "\n",
    "#If you want it for a specific workflow you can \"enable dev mode options\"\n",
    "#in the settings of the UI (gear beside the \"Queue Size: \") this will enable\n",
    "#a button on the UI to save workflows in api format.\n",
    "\n",
    "#keep in mind ComfyUI is pre alpha software so this format will change a bit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 500\n",
      "Response Headers: {'Content-Length': '55', 'Content-Type': 'text/plain; charset=utf-8', 'Date': 'Mon, 25 Dec 2023 00:22:10 GMT', 'Ngrok-Trace-Id': '5b8625c1d2ae3268523714eb2b347528', 'Server': 'Python/3.10 aiohttp/3.9.1'}\n",
      "Response Text: 500 Internal Server Error\n",
      "\n",
      "Server got itself in trouble\n",
      "Response is not JSON. Printed 'Response Text' above should give clues as to why.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Send Data to Endpoint and Receive Image Link\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the endpoint URL\n",
    "endpoint_url = \"https://5349-104-255-9-187.ngrok-free.app/prompt\"\n",
    "prompt = \"an ancient llamia monster\"\n",
    "model = \"LATENT\"\n",
    "\n",
    "# Define the data payload similar to the object outlined in the horde cell\n",
    "data_payload = {\n",
    "        \"sampler_name\": \"k_dpmpp_2m\",\n",
    "        \"cfg_scale\": 7.5,\n",
    "        \"denoising_strength\": 1.0,\n",
    "        \"seed\": 123456789,  # Replace with a dynamic seed if needed\n",
    "        \"height\": 512,\n",
    "        \"width\": 512,\n",
    "        \"karras\": False,\n",
    "        \"tiling\": False,\n",
    "        \"hires_fix\": False,\n",
    "        \"clip_skip\": 1,\n",
    "        \"control_type\": None,\n",
    "        \"image_is_control\": False,\n",
    "        \"return_control_map\": False,\n",
    "        \"prompt\": prompt,\n",
    "        \"ddim_steps\": 25,\n",
    "        \"n_iter\": 1,\n",
    "        \"model\": model,\n",
    "    }\n",
    "\n",
    "# Make the POST request to the endpoint\n",
    "response = requests.post(endpoint_url, json=data_payload)\n",
    "\n",
    "# Print the full response object for debugging\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response Headers:\", response.headers)\n",
    "print(\"Response Text:\", response.text)\n",
    "\n",
    "# Check if the request was successful\n",
    "try:\n",
    "    response_data = response.json()\n",
    "    print(\"JSON Response:\", json.dumps(response_data, indent=2))\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Response is not JSON. Printed 'Response Text' above should give clues as to why.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Image Generation Function using HordeLib\n",
    "import hordelib\n",
    "from hordelib.horde import HordeLib\n",
    "from hordelib.shared_model_manager import SharedModelManager\n",
    "\n",
    "# Initialize hordelib (Note: This will erase all command line arguments from argv)\n",
    "hordelib.initialise()\n",
    "# Assuming the necessary models are loaded and available in AIWORKER_CACHE_HOME\n",
    "def generate_image_with_hordelib(prompt, output_folder, model_name=\"Deliberate\"):\n",
    "    generate = HordeLib()\n",
    "    SharedModelManager.loadModelManagers(compvis=True)\n",
    "    SharedModelManager.manager.load(model_name)\n",
    "\n",
    "    data = {\n",
    "        \"sampler_name\": \"k_dpmpp_2m\",\n",
    "        \"cfg_scale\": 7.5,\n",
    "        \"denoising_strength\": 1.0,\n",
    "        \"seed\": 123456789,  # Replace with a dynamic seed if needed\n",
    "        \"height\": 512,\n",
    "        \"width\": 512,\n",
    "        \"karras\": False,\n",
    "        \"tiling\": False,\n",
    "        \"hires_fix\": False,\n",
    "        \"clip_skip\": 1,\n",
    "        \"control_type\": None,\n",
    "        \"image_is_control\": False,\n",
    "        \"return_control_map\": False,\n",
    "        \"prompt\": prompt,\n",
    "        \"ddim_steps\": 25,\n",
    "        \"n_iter\": 1,\n",
    "        \"model\": model_name,\n",
    "    }\n",
    "    pil_image = generate.basic_inference_single_image(data).image\n",
    "    image_path = os.path.join(output_folder, \"generated_image.png\")\n",
    "    pil_image.save(image_path)\n",
    "    return image_path\n",
    "\n",
    "# Example usage\n",
    "prompt = \"an ancient llamia monster\"\n",
    "image_path = generate_image_with_hordelib(prompt, IMAGE_OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Trulens and SQLite Integration\n",
    "\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up the path for the SQLite database\n",
    "DATABASE_FILE_PATH = Path(\"path/to/your/directory/default.sqlite\")  # Replace with the actual path to your directory\n",
    "\n",
    "# Function to create a new table in SQLite for each conversation\n",
    "def create_conversation_table(conversation_id):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(DATABASE_FILE_PATH)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Create a table for the conversation\n",
    "    table_name = f\"conversation_{conversation_id}\"\n",
    "    cur.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} (id INTEGER PRIMARY KEY, data TEXT);\")\n",
    "    \n",
    "    # Commit changes and close the connection\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "# Function to insert data into the conversation table\n",
    "def insert_into_conversation_table(conversation_id, data):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(DATABASE_FILE_PATH)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Insert data into the table\n",
    "    table_name = f\"conversation_{conversation_id}\"\n",
    "    cur.execute(f\"INSERT INTO {table_name} (data) VALUES (?);\", (data,))\n",
    "    \n",
    "    # Commit changes and close the connection\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "# Example usage\n",
    "conversation_id = \"12345\"  # Unique identifier for the conversation\n",
    "create_conversation_table(conversation_id)\n",
    "data_entry = json.dumps({'text_response': 'Example response', 'image_path': 'path/to/image.png'})\n",
    "insert_into_conversation_table(conversation_id, data_entry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
